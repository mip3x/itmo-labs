<center>Университет ИТМО<br>Факультет программной инженерии и компьютерной техники</center>

--------------------------------------------------------

Группа:
Студент:
Преподаватель:

<center>Отчёт по лабораторной работе<br>«Решение системы линейных алгебраических уравнений СЛАУ»</center>

<div class="page-break" style="page-break-before: always;"></div>


# Цель работы

Изучение численного метода Гаусса-Зейделя для решения систем линейных алгебраических уравнений (СЛАУ) и осуществление его программной реализации с возможностью анализа точности и сходимости итерационного процесса
# Описание метода

1. Начальное приближение – вектор правых частей эквивалетной СЛАУ (по сути, результат деления свободного коэффициента на множитель при $x_i$)
2. При вычислении $x_{i}^{k+1}$ на $k+1$ итерации используются $x_1^{k+1},x_2^{k+1},...,x_{i-1}^{k+1}$, которые были вычислены уже на этой итерации. Значения компонент, чей $i$ больше текущего, берутся из предыдущей итерации (при вычислении $x_{i+1}^{k+1}, x_{i+2}^{k+1},..., x_n^{k+1}$)
3. Условие окончания итерационного процесса: $$max(|x_i^{k}-x_i^{k-1}|)<\varepsilon$$
## Пример решения:
- Исходная система
$$
\begin{cases}
5x_1 - x_2 + 3x_3 = 5 \\
x_1 - 4x_2 + 2x_3 = 20 \\
2x_1 - x_2 + 5x_3 = 10
\end{cases}
$$
- Преобразование системы для метода Гаусса-Зейделя
$$
\begin{cases}
x_1^{(k)} = \frac{5 + x_2^{(k-1)} - 3x_3^{(k-1)}}{5} \\
x_2^{(k)} = \frac{20 - x_1^{(k)} - 2x_3^{(k-1)}}{-4} \\
x_3^{(k)} = \frac{10 - 2x_1^{(k)} + x_2^{(k)}}{5}
\end{cases}
$$
- Нулевое приближение ($\frac{b_i}{a_i}$)
$$
\begin{cases}
x_1^{(0)} = \frac{5}{5} = 1 \\
x_2^{(0)} = \frac{20}{-4} = -5 \\
x_3^{(0)} = \frac{10}{5} = 2
\end{cases}
$$
- Первое приближение
$$
\begin{cases}
x_1^{(1)} = \frac{5 + x_2^{(0)} - 3x_3^{(0)}}{5} = \frac{5 + (-5) - 3 \cdot 2}{5} = \frac{-6}{5} = -1.2 \\
x_2^{(1)} = \frac{20 - x_1^{(1)} - 2x_3^{(0)}}{-4} = \frac{20 + 1.2 - 4}{-4} = \frac{17.2}{-4} = -4.3 \\
x_3^{(1)} = \frac{10 - 2x_1^{(1)} + x_2^{(1)}}{5} = \frac{10 - 2(-1.2) + (-4.3)}{5} = \frac{10 + 2.4 - 4.3}{5} = \frac{8.1}{5} = 1.62
\end{cases}
$$
- Второе приближение (только шаблон)
$$
\begin{cases}
x_1^{(2)} = \frac{5 + x_2^{(1)} - 3x_3^{(1)}}{5} \\
x_2^{(2)} = \frac{20 - x_1^{(2)} - 2x_3^{(1)}}{-4} \\
x_3^{(2)} = \frac{10 - 2x_1^{(2)} + x_2^{(2)}}{5}
\end{cases}
$$
- Третье приближение (только шаблон)
$$
\begin{cases}
x_1^{(3)} = \frac{5 + x_2^{(2)} - 3x_3^{(2)}}{5} \\
x_2^{(3)} = \frac{20 - x_1^{(3)} - 2x_3^{(2)}}{-4} \\
x_3^{(3)} = \frac{10 - 2x_1^{(3)} + x_2^{(3)}}{5}
\end{cases}
$$

И т.д. После пяти приближений, получив коэффициенты, можно будет посчитать получившийся ответ: $x_{1}-4x_2+2x_3=20$. Полученные приближённые значения после 5 итераций: $(-0.7353)-4(-4.4844)+2\cdot1.3972=19.99$ 

<div class="page-break" style="page-break-before: always;"></div>

# Программная реализация

```c fold title:solver.c
#include <math.h>
#include "../include/io.h"
#include "../include/solver.h"
#include "../include/common.h"
#include <stdio.h>

double** iteration_matrix_norm(double** A, size_t n) {
    double** C = allocate_matrix(n);
    if (!C) {
        err("Ошибка выделения памяти\n");
        return NULL;
    }

    for (size_t i = 0; i < n; i++) {
        double aii = A[i][i];
        if (fabs(aii) <= 0) {
            err("Нулевой или слишком маленький диагональный элемент A[%zu][%zu]\n", i, i);
            free_matrix(C, n);
            return NULL;
        }

        for (size_t j = 0; j < n; j++) {
            if (j == i) C[i][j] = 0.0;
            else C[i][j] = -A[i][j] / aii;
        }
    }

        debug(__func__, "нормализованная матрица:\n");
        for (size_t i = 0; i < n; i++) {
                for (size_t j = 0; j < n; j++) {
                    printf("%8.3lf ", C[i][j]);
                }
                printf("\n");
            }
    return C;
}

double matrix_infinity_norm(double** A, size_t n) {
    double norm = 0.0;
    for (size_t i = 0; i < n; i++) {
        double row_sum = 0.0;
        for (size_t j = 0; j < n; j++)
            row_sum += fabs(A[i][j]);
        if (row_sum > norm)
            norm = row_sum;
    }
    return norm;
}

int gauss_seidel(double** A, double* b, size_t n, double* x, double* errors, double epsilon, int max_iter) {
    int iterations = 0;
    int converged = 0;
    while (iterations < max_iter) {
        double max_error = 0.0;
        for (size_t i = 0; i < n; i++) {
            double old_x = x[i];
            double sum = 0.0;
            for (size_t j = 0; j < n; j++) {
                if (j != i) sum += A[i][j] * x[j];
            }
            x[i] = (b[i] - sum) / A[i][i];
            errors[i] = fabs(x[i] - old_x);
            if (errors[i] > max_error)
                max_error = errors[i];
        }
        iterations++;
        if (max_error < epsilon) {
            converged = 1;
            break;
        }
    }
    return converged ? iterations : -1;
}
```

```c title:dominance.c
#include "../include/dominance.h"
#include "../include/common.h"
#include <math.h> 
#include <stdbool.h>
#include <stdio.h>

static void swap_rows(double** A, size_t row1, size_t row2) {
    if (row1 == row2) return;
    double* temp = A[row1];
    A[row1] = A[row2];
    A[row2] = temp;
}

static void swap_b(double* b, size_t i, size_t j) {
    if (i == j) return;
    double tmp = b[i];
    b[i] = b[j];
    b[j] = tmp;
}

bool is_strictly_diagonally_dominant(double** A, size_t n) {
    for (size_t i = 0; i < n; i++) {
        double diag = fabs(A[i][i]);
        double off_diag_sum = 0.0;
        for (size_t j = 0; j < n; j++)
            if (j != i) off_diag_sum += fabs(A[i][j]);
        if (diag < off_diag_sum) return false;
    }
    return true;
}

bool try_make_diagonally_dominant(double** A, double* b, size_t n) {
    for (size_t i = 0; i < n; i++) {
        size_t pivot_row = i;
        double max_val = fabs(A[i][i]);

        for (size_t k = i + 1; k < n; k++) {
            double val = fabs(A[k][i]);
            if (val >= max_val) {
                max_val = val;
                pivot_row = k;
            }
        }
        if (pivot_row != i) {
            swap_rows(A, i, pivot_row);
            swap_b(b, i, pivot_row);
        }
    }
    debug(__func__, "new matrix\n");
    for (size_t i = 0; i < n; i++) {
        for (size_t j = 0; j < n; j++) {
            printf("%8.3lf ", A[i][j]);
        }
        printf("\n");
    }
    return is_strictly_diagonally_dominant(A, n);
}
```

<div class="page-break" style="page-break-before: always;"></div>

# Примеры и результаты работы программы

## Пример №1

### Ввод

``` title:matrix
5 -1 3
1 -4 2
2 -1 5
```

``` title:rpv
5 20 10
```

### Вывод

```
--- Решение СЛАУ методом Гаусса-Зейделя ---

Введите размер матрицы n: 3
Выберите источник ввода матрицы:
1) Стандартный ввод
2) Файл
Ваш выбор: 2
Введите имя файла для матрицы: matrix 

Прочитанная матрица A:
   5.000   -1.000    3.000 
   1.000   -4.000    2.000 
   2.000   -1.000    5.000 

Выберите источник ввода вектора правых частей b:
1) Стандартный ввод
2) Файл
Ваш выбор: 2
Введите имя файла для вектора b: rpv

Введите точность epsilon: 0.01 

Матрица обладает диагональным преобладанием.
[INFO (iteration_matrix_norm)] нормализованная матрица:

   0.000    0.200   -0.600 
   0.250    0.000    0.500 
  -0.400    0.200    0.000 

Норма матрицы A: 0.800000

Метод сошелся за 6 итераций.

Вектор неизвестных x:
x[0] = -0.735409
x[1] = -4.485886
x[2] = 1.396986

Вектор погрешностей:
sigma[0] = 0.000954
sigma[1] = 0.003364
sigma[2] = 0.001055
```

## Пример №2

### Ввод

``` title:matrix1
5 4 9
1 8 2
7 1 3
```

``` title:rpv1
1 2 3
```

### Вывод

```
--- Решение СЛАУ методом Гаусса-Зейделя ---

Введите размер матрицы n: 3
Выберите источник ввода матрицы:
1) Стандартный ввод
2) Файл
Ваш выбор: 2
Введите имя файла для матрицы: matrix1

Прочитанная матрица A:
   5.000    4.000    9.000 
   1.000    8.000    2.000 
   7.000    1.000    3.000 

Выберите источник ввода вектора правых частей b:
1) Стандартный ввод
2) Файл
Ваш выбор: 2
Введите имя файла для вектора b: rpv1

Введите точность epsilon: 0.001

Матрица не обладает диагональным преобладанием.
Пытаемся добиться диагонального преобладания...
[INFO (try_make_diagonally_dominant)] new matrix

   7.000    1.000    3.000 
   1.000    8.000    2.000 
   5.000    4.000    9.000 
Диагональное преобладание достигнуто после перестановок.
Обновленная матрица A:
   7.000    1.000    3.000 
   1.000    8.000    2.000 
   5.000    4.000    9.000 
[INFO (iteration_matrix_norm)] нормализованная матрица:

   0.000   -0.143   -0.429 
  -0.125    0.000   -0.250 
  -0.556   -0.444    0.000 

Норма матрицы A: 1.000000

Метод сошелся за 6 итераций.

Вектор неизвестных x:
x[0] = 0.516003
x[1] = 0.257981
x[2] = -0.290215

Вектор погрешностей:
sigma[0] = 0.000342
sigma[1] = 0.000227
sigma[2] = 0.000290
```

<div class="page-break" style="page-break-before: always;"></div>

# Вывод

В ходе лабораторной работы был изучен и реализован метод Гаусса-Зейделя. Полученные результаты показали сходимость итерационного метода при выполнении условия диагонального преобладания. Метод обеспечивает более быструю сходимость, чем метод простой итерации.
