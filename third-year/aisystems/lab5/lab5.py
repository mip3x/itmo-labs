# -*- coding: utf-8 -*-
"""lab5.ipynb

Automatically generated by Colab.

# Лабораторная 5. Деревья решений

Дерево решений - способ представления правил в иерархической последовательности, где каждому объекту соответствует узел, дающий решение

- Узел - признак
- Ребро - значение признака
- Лист - метка класса
"""

import pandas as pd

data = pd.read_csv("/content/agaricus-lepiota.csv", delimiter=",")
data

"""## Отобрать случайным образом sqrt(n) признаков

`classes` - целевая переменная:
- e = edible: съедобный
- p = poisonous: ядовитый

Из признаков случайным образом выберем `sqrt(n)`
"""

target_col = "classes"

feature_cols = [c for c in data.columns if c != target_col]
n = len(feature_cols)
n

"""Всего есть 22 признака"""

import numpy as np

k = int(np.ceil(np.sqrt(n))) # округлим в бОльшую сторону
rng = np.random.default_rng(seed=42)
selected = rng.choice(feature_cols, size=k, replace=False)

print("n =", n, "k =", k)
print("Выбранные признаки:", selected.tolist())

"""Выделим тестовые и обучающие наборы"""

X = data[selected].copy()
y = data["classes"].copy()

rng = np.random.default_rng(42)
idx = np.arange(len(data))
rng.shuffle(idx)

test_size = int(0.2 * len(data))
test_idx = idx[:test_size]
train_idx = idx[test_size:]

X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]
X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]

"""Заменим модой отсутствующие (обозначаются как "?" в датасете) значения"""

X_train = X_train.copy()
X_test = X_test.copy()

for col in selected:
    mode = X_train.loc[X_train[col] != "?", col].mode()
    if len(mode) == 0:
        continue
    fill_value = mode.iloc[0]

    X_train.loc[X_train[col] == "?", col] = fill_value
    X_test.loc[X_test[col] == "?", col] = fill_value

X_train

"""Проверим, что неизвестных значений нет:"""

print((X_train == "?").sum())
print((X_test == "?").sum())

"""Везде нули, значит, значения заменены

## Реализовать без использования сторонних библиотек построение дерева решений (дерево не бинарное, numpy и pandas использовать можно, использовать список списков для реализации дерева - нельзя) для решения задачи бинарной классификации
"""

class DecisionTreeNonBinary:
    def __init__(self, pos_label="p", max_depth=10, min_samples_split=2, min_gain_ratio=1e-12):
        self.pos_label = pos_label
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.min_gain_ratio = min_gain_ratio
        self.tree_ = None
        self.features_ = None

    def _build_tree(self, X: pd.DataFrame, y: pd.Series, features: list[str], depth: int = 0):
        # стоп 1: узел чистый
        if y.nunique() <= 1:
            return self._make_leaf(y)

        # стоп 2: достигли глубины
        if depth >= self.max_depth:
            return self._make_leaf(y)

        # стоп 3: мало объектов
        if len(y) < self.min_samples_split:
            return self._make_leaf(y)

        # стоп 4: признаки закончились
        if len(features) == 0:
            return self._make_leaf(y)

        # выбираем лучший признак по C4.5
        best_f, best_gr = self._best_feature_c45(X, y, features)

        # стоп 5: нет смысла делить
        if best_f is None or best_gr < self.min_gain_ratio:
            return self._make_leaf(y)

        node = {
            "type": "node",
            "feature": best_f,
            "children": {},
            # fallback на случай "неизвестного" значения в test:
            "default_class": self._majority_class(y),
            "default_proba_pos": self._proba_pos(y),
            "n": int(len(y)),
            "depth": depth,
            "gain_ratio": float(best_gr),
        }

        # (обычно в C4.5 категориальный признак после использования убирают)
        next_features = [f for f in features if f != best_f]

        # строим небинарные ветки
        for val, idx in X.groupby(best_f).groups.items():
            X_sub = X.loc[idx]
            y_sub = y.loc[idx]
            node["children"][val] = self._build_tree(X_sub, y_sub, next_features, depth + 1)

        return node

    def fit(self, X: pd.DataFrame, y: pd.Series, features=None):
        if features is None:
            features = list(X.columns)
        self.features_ = list(features)
        self.tree_ = self._build_tree(X, y, self.features_, depth=0)
        return self

    def _predict_one(self, row: pd.Series):
        node = self.tree_
        while node["type"] != "leaf":
            f = node["feature"]
            v = row[f]
            child = node["children"].get(v)
            if child is None:
                return node["default_class"]
            node = child
        return node["class"]

    def _predict_proba_one(self, row: pd.Series):
        node = self.tree_
        while node["type"] != "leaf":
            f = node["feature"]
            v = row[f]
            child = node["children"].get(v)
            if child is None:
                return float(node["default_proba_pos"])
            node = child
        return float(node["proba_pos"])

    def predict(self, X: pd.DataFrame):
        if self.tree_ is None:
            raise RuntimeError("Call fit() first")
        return X.apply(lambda r: self._predict_one(r), axis=1)

    def predict_proba(self, X: pd.DataFrame):
        if self.tree_ is None:
            raise RuntimeError("Call fit() first")
        return X.apply(lambda r: self._predict_proba_one(r), axis=1)

    def _majority_class(self, y: pd.Series):
        """
        Возвращает класс, который встречается чаще всего в y.
        Это нужно, когда мы делаем лист: "если не знаем что делать — выбираем большинство".
        """
        return y.value_counts().idxmax()

    def _proba_pos(self, y: pd.Series) -> float:
        """
        Возвращает вероятность положительного класса:
        P(y == pos_label).

        Например, если y = [p, e, p, p] и pos_label='p',
        то proba = 3/4 = 0.75
        """
        if len(y) == 0:
            return 0.0
        return float((y == self.pos_label).mean())

    def _make_leaf(self, y: pd.Series):
        """
        Создаёт лист дерева.

        Leaf хранит:
        - type: "leaf"   (чтобы отличать от внутреннего узла)
        - class: предсказанный класс (majority)
        - proba_pos: вероятность положительного класса
        - n: сколько объектов дошло до этого листа
        - counts: сколько объектов каждого класса
        """
        counts = y.value_counts().to_dict()
        return {
            "type": "leaf",
            "class": self._majority_class(y),
            "proba_pos": self._proba_pos(y),
            "n": int(len(y)),
            "counts": counts,
        }

    def _entropy(self, y: pd.Series) -> float:
        """
        Энтропия Шеннона для меток классов в y.
        H(S) = - sum_k ( p_k * log2(p_k) )
        """
        n = len(y)
        if n == 0:
            return 0.0

        # p_k = частота класса / n
        probs = (y.value_counts() / n).to_numpy()

        # убираем нули, чтобы не считать log2(0)
        probs = probs[probs > 0]

        return float(-(probs * np.log2(probs)).sum())

    def _conditional_entropy(self, X: pd.DataFrame, y: pd.Series, feature: str) -> float:
        """H(S | A) = sum_v (|S_v|/|S|) * H(S_v)"""
        total = len(y)
        if total == 0:
            return 0.0

        h = 0.0
        for val, idx in X.groupby(feature).groups.items():
            y_sub = y.loc[idx]
            w = len(y_sub) / total
            h += w * self._entropy(y_sub)
        return float(h)

    def _information_gain(self, X: pd.DataFrame, y: pd.Series, feature: str) -> float:
        """IG(S,A) = H(S) - H(S|A)"""
        return float(self._entropy(y) - self._conditional_entropy(X, y, feature))

    def _split_info(self, X: pd.DataFrame, feature: str) -> float:
        """SplitInfo(S,A) = - sum_v (|S_v|/|S|) * log2(|S_v|/|S|)"""
        total = len(X)
        if total == 0:
            return 0.0

        si = 0.0
        for val, idx in X.groupby(feature).groups.items():
            p = len(idx) / total
            if p > 0:
                si -= p * np.log2(p)
        return float(si)

    def _gain_ratio(self, X: pd.DataFrame, y: pd.Series, feature: str) -> float:
        """GR = IG / SplitInfo (если SplitInfo=0, то GR=0)"""
        ig = self._information_gain(X, y, feature)
        si = self._split_info(X, feature)
        if si == 0.0:
            return 0.0
        return float(ig / si)

    def _best_feature_c45(self, X: pd.DataFrame, y: pd.Series, features: list[str]):
        """Выбор атрибута с максимальным Gain Ratio"""
        best_f = None
        best_gr = -1.0
        for f in features:
            gr = self._gain_ratio(X, y, f)
            if gr > best_gr:
                best_gr = gr
                best_f = f
        return best_f, float(best_gr)

    def print_tree(self, node=None, indent=""):
        if node is None:
            node = self.tree_
        if node is None:
            print("<empty tree>")
            return

        if node["type"] == "leaf":
            print(
                f"{indent}LEAF: class={node['class']} "
                f"proba_p={node['proba_pos']:.3f} n={node['n']} counts={node['counts']}"
            )
            return

        # node
        f = node["feature"]
        print(
            f"{indent}NODE: feature={f} "
            f"(GR={node.get('gain_ratio', float('nan')):.6f}, n={node.get('n','?')}) "
            f"default={node.get('default_class')} proba_p={node.get('default_proba_pos', float('nan')):.3f}"
        )

        for val in sorted(node["children"].keys()):
            print(f"{indent}  IF {f} == {val}:")
            self.print_tree(node["children"][val], indent + "    ")

dt = DecisionTreeNonBinary(pos_label="p")

dt.fit(X_train, y_train, features=list(selected))

y_pred = dt.predict(X_test)
y_score = dt.predict_proba(X_test)

print(y_pred.head())
print(y_score.head())

dt.print_tree()

"""## Провести оценку реализованного алгоритма с использованием Accuracy, precision и recall

Рассмотрим данную бинарную классификацию:

- положительный класс: p (poisonous)
- отрицательный класс: e (edible)

Дадим определения:

Предсказали p	Предсказали e

Истинно p	TP	FN

Истинно e	FP	TN

Где:
- TP - ядовитый -> предсказан как ядовитый
- FP - съедобный -> предсказан как ядовитый
- FN - ядовитый -> предсказан как съедобный
- TN - съедобный -> предсказан как съедобный
"""

def confusion_counts(y_true, y_pred, pos_label="p"):
    TP = FP = FN = TN = 0

    for yt, yp in zip(y_true, y_pred):
        if yt == pos_label and yp == pos_label:
            TP += 1
        elif yt != pos_label and yp == pos_label:
            FP += 1
        elif yt == pos_label and yp != pos_label:
            FN += 1
        else:
            TN += 1

    return TP, FP, FN, TN

def precision_score(TP, FP):
    denom = TP + FP
    if denom == 0:
        return 0.0
    return TP / denom

def accuracy_score(TP, FP, FN, TN):
    total = TP + FP + FN + TN
    if total == 0:
        return 0.0
    return (TP + TN) / total

def recall_score(TP, FN):
    denom = TP + FN
    if denom == 0:
        return 0.0
    return TP / denom

TP, FP, FN, TN = confusion_counts(y_test, y_pred, pos_label="p")

acc = accuracy_score(TP, FP, FN, TN)
prec = precision_score(TP, FP)
rec = recall_score(TP, FN)

print(f"Accuracy : {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall   : {rec:.4f}")

"""`Accuracy` показывает общую долю правильных классификаций.

`Precision` отражает долю корректных предсказаний ядовитых грибов среди всех предсказанных как ядовитые.

`Recall` показывает способность модели обнаруживать все ядовитые грибы.

Полученные результаты показывают высокую точность классификации (`Accuracy` ~= 91.6%).
Значение `Precision` ~= 99.2% свидетельствует о том, что модель практически не допускает ложных срабатываний при определении ядовитых грибов.
Однако значение `Recall` ~= 83.1% указывает на то, что часть ядовитых грибов всё же классифицируется как съедобные, что является критичной ошибкой для данной задачи.
Таким образом, модель склонна к консервативному поведению, минимизируя ложные срабатывания, но не обеспечивая полного охвата положительного класса.

## Построить кривые AUC-ROC и AUC-PR



AUC-ROC - это метрика, используемая для оценки качества бинарной классификационной модели

График зависимости True Positive Rate от False Positive Rate при изменении порога классификации

AUC-PR - это метрика, также используемая для оценки качества бинарной классификационной модели, особенно в случаях, когда классы несбалансированы.

График зависимости `Precision` (точности) от `Recall` (полноты) при изменении порога классификации.

`TPR` = `TP / (TP + FN)`

`FPR` = `FP / (FP + TN)`
"""

import matplotlib.pyplot as plt

def roc_pr_curves(y_true, y_score, pos_label="p"):
    y_true = np.asarray(y_true)
    y_score = np.asarray(y_score, dtype=float)

    y_bin = (y_true == pos_label).astype(int)

    order = np.argsort(-y_score)
    y_bin = y_bin[order]
    y_score = y_score[order]

    P = y_bin.sum()          # сколько положительных
    N = len(y_bin) - P       # сколько отрицательных

    if P == 0 or N == 0:
        raise ValueError("ROC/PR не определены, если в y_true только один класс.")

    tp = 0
    fp = 0

    # точки кривых
    roc_fpr = [0.0]
    roc_tpr = [0.0]

    pr_recall = [0.0]
    pr_precision = [1.0]

    prev_score = None

    for i in range(len(y_bin)):
        score = y_score[i]
        label = y_bin[i]

        # если score сменился, фиксируем точку ДО добавления новых с этим score
        if prev_score is not None and score != prev_score:
            tpr = tp / P
            fpr = fp / N
            roc_fpr.append(fpr)
            roc_tpr.append(tpr)

            prec = tp / (tp + fp) if (tp + fp) > 0 else 1.0
            rec = tp / P
            pr_recall.append(rec)
            pr_precision.append(prec)

        # объект теперь считается предсказанным positive
        if label == 1:
            tp += 1
        else:
            fp += 1

        prev_score = score

    # добавляем последнюю точку (после обработки всех)
    tpr = tp / P
    fpr = fp / N
    roc_fpr.append(fpr)
    roc_tpr.append(tpr)

    prec = tp / (tp + fp) if (tp + fp) > 0 else 1.0
    rec = tp / P
    pr_recall.append(rec)
    pr_precision.append(prec)

    roc_auc = np.trapz(roc_tpr, roc_fpr)

    pr_auc = np.trapz(pr_precision, pr_recall)

    return (np.array(roc_fpr), np.array(roc_tpr), roc_auc,
            np.array(pr_recall), np.array(pr_precision), pr_auc)

roc_fpr, roc_tpr, roc_auc, pr_rec, pr_prec, pr_auc = roc_pr_curves(
    y_test, y_score, pos_label="p"
)

print(f"AUC-ROC = {roc_auc:.4f}")
print(f"AUC-PR  = {pr_auc:.4f}")

# --- графики ---
plt.figure()
plt.plot(roc_fpr, roc_tpr)
plt.xlabel("FPR")
plt.ylabel("TPR (Recall)")
plt.title(f"ROC curve (AUC={roc_auc:.4f})")
plt.grid(True)
plt.show()

plt.figure()
plt.plot(pr_rec, pr_prec)
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title(f"PR curve (AUC={pr_auc:.4f})")
plt.grid(True)
plt.show()
